{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Diabetes Prediction - Modeling\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Training and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "datapath = '../data'\n",
    "datapath_X_train = os.path.join(datapath, 'X_train.csv')\n",
    "datapath_X_test = os.path.join(datapath, 'X_test.csv')\n",
    "datapath_y_train = os.path.join(datapath, 'y_train.csv')\n",
    "datapath_y_test = os.path.join(datapath, 'y_test.csv')\n",
    "\n",
    "X_train = pd.read_csv(datapath_X_train)\n",
    "X_test = pd.read_csv(datapath_X_test)\n",
    "y_train = pd.read_csv(datapath_y_train)\n",
    "y_test = pd.read_csv(datapath_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Classifiers Using a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the Pipeline**\n",
    "Set up our pipeline.  We're going to do a gridsearch with 5-fold cross validation and:\n",
    "- scale our data using Standard Scaler\n",
    "- impute our data with KnnImputer\n",
    "- train our classifier with various parameters using \"recall\" as our scoring metric. We want to use recall because we want to minimize false negatives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for KNN Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('Knn', KNeighborsClassifier())]\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with features of Glucose and BMI Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        89\n",
      "           1       0.68      0.62      0.65        58\n",
      "\n",
      "    accuracy                           0.73       147\n",
      "   macro avg       0.72      0.71      0.72       147\n",
      "weighted avg       0.73      0.73      0.73       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 9, 'Knn__n_neighbors': 3}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[72 17]\n",
      " [22 36]]\n"
     ]
    }
   ],
   "source": [
    "# Let's try a model based on just Glucose and BMI Category\n",
    "features = ['Glucose',\n",
    "       'BMI Category_Class II Obese', 'BMI Category_Class III Obese',\n",
    "       'BMI Category_Normal Weight', 'BMI Category_Overweight',\n",
    "       'BMI Category_Underweight']\n",
    "\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Knn__n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "knn_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recall score for an outcome of 1 is .62 and our overall accuracy is .73.  Let's try another model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with all features except continuous BMI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        89\n",
      "           1       0.80      0.62      0.70        58\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.79      0.76      0.77       147\n",
      "weighted avg       0.79      0.79      0.78       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 9, 'Knn__n_neighbors': 5}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  9]\n",
      " [22 36]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's try it with all the features except BMI (which is highly correlated with BMI Category)\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\\\n",
    "       'DiabetesPedigreeFunction', 'Age', \\\n",
    "       'BMI Category_Class II Obese', 'BMI Category_Class III Obese',\\\n",
    "       'BMI Category_Normal Weight', 'BMI Category_Overweight',\\\n",
    "       'BMI Category_Underweight']\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Knn__n_neighbors': [3, 5, 7, 9]}   \n",
    "\n",
    "knn_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting.  Our recall score hasn't improved, but our overall accuracy has improved with the additional features.  Let's keep all those features going forward.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        89\n",
      "           1       0.80      0.62      0.70        58\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.79      0.76      0.77       147\n",
      "weighted avg       0.79      0.79      0.78       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 9, 'Knn__n_neighbors': 5, 'Knn__p': 2}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  9]\n",
      " [22 36]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's try comparing Manhattan or Euclidean distance for our classifier\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Knn__n_neighbors': [3, 5, 7, 9], 'Knn__p': [1, 2]}   \n",
    "\n",
    "knn_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have made no difference, and the euclidean distance is actually the better performer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Let's try a decision tree with a hyperparameters of max_depth and criterion (\"entropy\" or \"gini\").  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Decision Tree Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('Tree', DecisionTreeClassifier())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        89\n",
      "           1       0.70      0.64      0.67        58\n",
      "\n",
      "    accuracy                           0.75       147\n",
      "   macro avg       0.74      0.73      0.73       147\n",
      "weighted avg       0.75      0.75      0.75       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 3, 'Tree__criterion': 'entropy', 'Tree__max_depth': 5}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[73 16]\n",
      " [21 37]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Tree__max_depth': [3, 5, 7], 'Tree__criterion': ['entropy', 'gini']}   \n",
    "\n",
    "tree_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of this classifier is slightly worse than our KNN, but note that our recall score for an outcome of 1 has improved, and we have fewer false negatives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "Let's try a random forest classifier.  We expect this would do much better than a simple decision tree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Random Forest Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()),('RF', RandomForestClassifier())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80        89\n",
      "           1       0.74      0.53      0.62        58\n",
      "\n",
      "    accuracy                           0.74       147\n",
      "   macro avg       0.74      0.71      0.71       147\n",
      "weighted avg       0.74      0.74      0.73       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 3, 'RF__criterion': 'gini', 'RF__max_depth': 7, 'RF__n_estimators': 400}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[78 11]\n",
      " [27 31]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = { 'Imputer__n_neighbors': [3,5,7], 'RF__max_depth': [3, 5, 7], \\\n",
    "              'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200, 300,400]}   \n",
    "\n",
    "RF_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, our random forest classifier is worse than our single decision tree in terms of our recall score, although similar in terms of accuracy. I'm curious if we increased the max depth whether it would improve.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        89\n",
      "           1       0.77      0.57      0.65        58\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.76      0.73      0.74       147\n",
      "weighted avg       0.76      0.76      0.75       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 7, 'RF__criterion': 'entropy', 'RF__max_depth': 9, 'RF__n_estimators': 400}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[79 10]\n",
      " [25 33]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = { 'Imputer__n_neighbors': [3,5,7], 'RF__max_depth': [5, 7, 9], \\\n",
    "              'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200, 300,400]}   \n",
    "\n",
    "RF_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seemed to prefer a deeper tree, but the recall score only improved marginally.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBC_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Gradient Boosting Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('GBC', GradientBoostingClassifier())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83        89\n",
      "           1       0.78      0.60      0.68        58\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.78      0.75      0.75       147\n",
      "weighted avg       0.78      0.78      0.77       147\n",
      "\n",
      "Tuned Model Parameters: {'GBC__learning_rate': 0.75, 'GBC__max_depth': 2, 'GBC__max_features': 5, 'GBC__n_estimators': 50, 'Imputer__n_neighbors': 9}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[79 10]\n",
      " [23 35]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'GBC__n_estimators': [20, 50], \\\n",
    "              'GBC__learning_rate': [0.05, 0.1, 0.25, 0.5, 0.75, 1], 'GBC__max_features': [2, 5], 'GBC__max_depth': [2, 5]}   \n",
    "\n",
    "GBC_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the gradient boosing classifier, notice that our overall accuracy and our recall score are slightly higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Support Vector Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recallscore as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('SVC', SVC(gamma='scale', kernel='rbf'))]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81        89\n",
      "           1       0.71      0.67      0.69        58\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.75      0.75      0.75       147\n",
      "weighted avg       0.76      0.76      0.76       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 3, 'SVC__C': 10}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[73 16]\n",
      " [19 39]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'SVC__C': [.1, 1, 10]}   \n",
    "\n",
    "SVC_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier actually does quite well, with a comparable accuracy score and a higher and a recall score that are better than our random forest classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logreg_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Random Forest Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('Logreg', LogisticRegression())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82        89\n",
      "           1       0.76      0.60      0.67        58\n",
      "\n",
      "    accuracy                           0.77       147\n",
      "   macro avg       0.77      0.74      0.75       147\n",
      "weighted avg       0.77      0.77      0.76       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 3, 'Logreg__C': 10}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[78 11]\n",
      " [23 35]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Logreg__C': [0.001, 0.1, 1, 10, 100]}   \n",
    "\n",
    "Logreg_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression seems to do better than Random Forest, but not quite as well as SVC.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing our Dataset using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that SVC performs the best, followed by logistic regression and then random forest.  However, for all of these we are still seeing a fairly large number of false negatives, with relatively low recall scores.  This is interesting given that we are using recall as our scoring metric, but note that generally we're seeing precision and recall scores that are much higher for an outcome of 0 than 1.  I believe this makes sense becuase 2/3 of our data has an outcome of 0. So let's try oversampling the data in order to lead to a more balanced dataset.\n",
    "\n",
    "In order to do this we'll use SMOTE, which means we have to use the pipeline from imblearn.  This is so that only the training data is oversampled but the test data is not.  \n",
    "\n",
    "Let's try SMOTE and then re-run our three top classifiers and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Random Forest Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('smote',SMOTE()),('RF', RandomForestClassifier())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.80        89\n",
      "           1       0.67      0.86      0.75        58\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.78      0.79      0.77       147\n",
      "weighted avg       0.80      0.78      0.78       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 7, 'RF__criterion': 'gini', 'RF__max_depth': 3, 'RF__n_estimators': 400}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[64 25]\n",
      " [ 8 50]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = { 'Imputer__n_neighbors': [3,5,7], 'RF__max_depth': [3, 5, 7], \\\n",
    "              'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200, 300,400]}   \n",
    "\n",
    "RF_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is significantly better.  Note that our overall accuracy score has increased to .78, but more remarkably our recall score for an outome of 1 has increased to .86. \n",
    "\n",
    "Let's try to further optimize our Random Forest Classifier by exploring the hyperparameter space and specifying different sets of features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80        89\n",
      "           1       0.67      0.88      0.76        58\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.79      0.80      0.78       147\n",
      "weighted avg       0.81      0.78      0.78       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 7, 'RF__criterion': 'gini', 'RF__max_depth': 3, 'RF__n_estimators': 300}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[64 25]\n",
      " [ 7 51]]\n"
     ]
    }
   ],
   "source": [
    "# Let's expand the hyperparameter space a bit. \n",
    "parameters = { 'Imputer__n_neighbors': [3,5,7,9], 'RF__max_depth': [3, 5, 7, 9], \\\n",
    "              'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200, 300, 400, 500]}   \n",
    "\n",
    "RF_pipeline(X_train, X_test, y_train, y_test, features, parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using 500 estimates results in slightly better recall scores, but it is a lot slower!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.71      0.80        89\n",
      "           1       0.67      0.91      0.77        58\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.80      0.81      0.79       147\n",
      "weighted avg       0.83      0.79      0.79       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 9, 'RF__criterion': 'entropy', 'RF__max_depth': 3, 'RF__n_estimators': 500}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[63 26]\n",
      " [ 5 53]]\n"
     ]
    }
   ],
   "source": [
    "# Let's try continuous BMI instead of BMI Category\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\\\n",
    "       'DiabetesPedigreeFunction', 'Age', 'BMI']\n",
    "\n",
    "# Let's use the same hyperparameter space. \n",
    "parameters = { 'Imputer__n_neighbors': [3,5,7,9], 'RF__max_depth': [3, 5, 7, 9], \\\n",
    "              'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200, 300, 400, 500]}   \n",
    "\n",
    "RF_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting, both accuracy and recall improved a bit.  However I think making BMI a category is more interesting so we'll stick with that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to optimize our SVC using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Support Vector Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('smote',SMOTE()), ('SVC', SVC())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81        89\n",
      "           1       0.71      0.67      0.69        58\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.75      0.75      0.75       147\n",
      "weighted avg       0.76      0.76      0.76       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 3, 'SVC__C': 10, 'SVC__gamma': 'scale', 'SVC__kernel': 'rbf'}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[73 16]\n",
      " [19 39]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\\\n",
    "       'DiabetesPedigreeFunction', 'Age', \\\n",
    "       'BMI Category_Class II Obese', 'BMI Category_Class III Obese',\\\n",
    "       'BMI Category_Normal Weight', 'BMI Category_Overweight',\\\n",
    "       'BMI Category_Underweight']\n",
    "\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'SVC__C': [.1, 1, 10], 'SVC__kernel': ['rbf','poly'],\\\n",
    "             'SVC__gamma': ['scale','auto']}   \n",
    "\n",
    "SVC_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, our SVC did not respond as well to SMOTE as our random forest model. \n",
    "\n",
    "Let's try Logistic Regression with SMOTE as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logreg_pipeline(X_train, X_test, y_train, y_test, features, params):\n",
    "    \"\"\"This runs a pipeline for Random Forest Classification\n",
    "    based on a subset of features.\n",
    "    It uses the recall score as the metric for optimizing the classifier\"\"\"\n",
    "    \n",
    "    # Subset X\n",
    "    # Here we select the subset of features that we would like\n",
    "    X_train = np.array(X_train[features])\n",
    "    X_test = np.array(X_test[features])\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "        \n",
    "    # Setup the pipeline\n",
    "    steps = [('scaler',StandardScaler()),('Imputer', KNNImputer()), ('smote',SMOTE()),('Logreg', LogisticRegression())]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Instantiate the GridSearchCV object: cv\n",
    "    cv = GridSearchCV(pipeline, params, cv=5, scoring='recall')\n",
    "\n",
    "    # Fit to the training set\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict our test data\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82        89\n",
      "           1       0.71      0.83      0.76        58\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.79      0.80      0.79       147\n",
      "weighted avg       0.81      0.80      0.80       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 7, 'Logreg__C': 0.1}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[69 20]\n",
      " [10 48]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Logreg__C': [0.001, 0.1, 1, 10, 100]}   \n",
    "\n",
    "Logreg_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not do as well as Random Forest but outperforms SVC. It is possible that we could improve our logistic regression model if we were to do a log transform on some of the feature variables. That, however, I will leave for another time, as I'm happy with the performance of the Random Forest Classifier now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try log-transforming Insulin and Diabetes Pedigree Function \n",
    "X_train['log_Insulin']=np.log(X_train['Insulin'])\n",
    "X_test['log_Insulin']=np.log(X_test['Insulin'])\n",
    "\n",
    "X_train['log_DPF']=np.log(X_train['DiabetesPedigreeFunction'])\n",
    "X_test['log_DPF']=np.log(X_test['DiabetesPedigreeFunction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80        89\n",
      "           1       0.68      0.83      0.74        58\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.77      0.78      0.77       147\n",
      "weighted avg       0.79      0.78      0.78       147\n",
      "\n",
      "Tuned Model Parameters: {'Imputer__n_neighbors': 7, 'Logreg__C': 0.1}\n",
      "\n",
      "Confusion Matrix: \n",
      " [[66 23]\n",
      " [10 48]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the features to select these log transforms instead\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'log_Insulin',\\\n",
    "       'log_DPF', 'Age', \\\n",
    "       'BMI Category_Class II Obese', 'BMI Category_Class III Obese',\\\n",
    "       'BMI Category_Normal Weight', 'BMI Category_Overweight',\\\n",
    "       'BMI Category_Underweight']\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'Imputer__n_neighbors': [3, 5, 7, 9], 'Logreg__C': [0.001, 0.1, 1, 10, 100]}   \n",
    "\n",
    "Logreg_pipeline(X_train, X_test, y_train, y_test, features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that actually didn't help.  Our recall score stayed the same but our overall accuracy went down.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Random Forest Model is our clear best performer in terms of accuracy score and recall score.  This model is also intuitive and easy to explain.  \n",
    "\n",
    "Note that because we optimizing based on recall score, we are choosing to accept a fair number of false positives.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit our final model on our final set of features, \n",
    "# our tuned hyperparameters, and our entire dataset\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = np.array(pd.concat([y_train, y_test])).ravel()\n",
    "\n",
    "# Our final set of features\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\\\n",
    "       'DiabetesPedigreeFunction', 'Age', \\\n",
    "       'BMI Category_Class II Obese', 'BMI Category_Class III Obese',\\\n",
    "       'BMI Category_Normal Weight', 'BMI Category_Overweight',\\\n",
    "       'BMI Category_Underweight']\n",
    "\n",
    "# Actually, for RF we don't need to scale the data so we can skip that step\n",
    "\n",
    "# But we'll impute the data \n",
    "imputer = KNNImputer(n_neighbors = 7)\n",
    "X_imp = imputer.fit_transform(X[features])\n",
    "\n",
    "# And SMOTE the data\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X_imp, y)\n",
    "\n",
    "# And finally fit our classifier\n",
    "RF = RandomForestClassifier(max_depth= 3, criterion = 'entropy', n_estimators = 500)  \n",
    "final_model = RF.fit(X_sm, y_sm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score:\n",
      " 0.791\n",
      "Average recall score:\n",
      " 0.8389999999999999\n"
     ]
    }
   ],
   "source": [
    "# Let's just test this model's accuracy as a sanity check against a random 50% of the data\n",
    "# multiple times\n",
    "\n",
    "accuracy_scores=[]\n",
    "recall_scores=[]\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[features], y, test_size = .5)\n",
    "\n",
    "    # Predict our test data\n",
    "    X_test_imp = imputer.fit_transform(X_test)\n",
    "    y_pred = final_model.predict(X_test_imp)\n",
    "\n",
    "    # Compute and print metrics\n",
    "    accuracy_scores.append(round(accuracy_score(y_test, y_pred),2))\n",
    "    recall_scores.append(round(recall_score(y_test, y_pred),2))\n",
    "    \n",
    "print('Average accuracy score:\\n', np.mean(accuracy_scores))\n",
    "print('Average recall score:\\n', np.mean(recall_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scores are slightly lower than what we saw from our model as optimized on the training set.  I believe this makes sense, because when trained on all of the data, we will end up with a slightly different estimator.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score:  0.8306254029658285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = final_model.predict_proba(X_test_imp)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr, tpr, label='Random Forest')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve');\n",
    "\n",
    "print(\"ROC score: \", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              importance\n",
      "Glucose                         0.257037\n",
      "Insulin                         0.210925\n",
      "Age                             0.172250\n",
      "SkinThickness                   0.081292\n",
      "BMI Category_Normal Weight      0.079603\n",
      "Pregnancies                     0.075036\n",
      "DiabetesPedigreeFunction        0.052198\n",
      "BMI Category_Overweight         0.033086\n",
      "BloodPressure                   0.019341\n",
      "BMI Category_Class III Obese    0.012013\n",
      "BMI Category_Class II Obese     0.007181\n",
      "BMI Category_Underweight        0.000038\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(final_model.feature_importances_, index = features,\\\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Glucose was the most important feature, followed by Insulin and Age.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "modelpath = '../models/final_model.pkl'\n",
    "with open(modelpath, 'wb') as f:\n",
    "    pickle.dump(final_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TestEnv] *",
   "language": "python",
   "name": "conda-env-TestEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
